{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:**  Thomas Duthoit<br>\n",
    "**Copyright:** 2022 Thomas Duthoit <br>\n",
    "**License:** MIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Anomaly detection in satellite image time series related to forest monitoring<\\h1><\\center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data used in this notebook\n",
    "\n",
    "| Product Description | WEkEO HDA ID | WEkEO metadata |\n",
    "|:--------------------:|:-----------------:|:-----------------:|\n",
    "| Sentinel-2 MSI level-1C | EO:EUM:DAT:0411 | <a href=\"https://navigator.eumetsat.int/product/EO:EUM:DAT:SENTINEL-3:SL_1_RBT___NTC?query=SLSTR&s=advanced\" target=\"_blank\">link</a> | EO:ESA:DAT:SENTINEL-2:MSI | <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AESA%3ADAT%3ASENTINEL-2%3AMSI\" target=\"_blank\">link</a> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning outcomes\n",
    "\n",
    "At the end of this notebook you will know;\n",
    "* How a certain type of data is collected by satellites.\n",
    "* How you can use a certain type of data for a specific environmental application.\n",
    "* How to visualise a certain type of data.\n",
    "* How to analyse a certain type of data with a certain type of method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook outline\n",
    "    \n",
    " 1. [Load Sentinel-2 level 1C tiles on WEkEO's catalogue](#section1)\n",
    " 2. [Generate the time series : compute NDVI and cloud mask](#section2)\n",
    " 3. [Superpixel segmentation of the area of interest](#section3)\n",
    " 4. [Compute the NDVI mean and cloud mask mean for each superpixel](#section4)\n",
    " 5. [Filtering : keep only forest superpixels](#section5)\n",
    " 6. [Apply BFAST algorithm to all remaining time series](#section6)\n",
    " 7. [USE CASE 1 : Forest fire detection in Var region (France)](#section7)\n",
    " 8. [USE CASE 2 : Monitor parasite attacks on trees, example in Lot region (France)](#section8)\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports (some common examples used and available on the WEkEO Jupyter Lab)\n",
    "import cartopy.crs as ccrs\n",
    "import glob\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import xarray as xr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='section1'></a>1. Load Sentinel-2 level 1C tiles on WEkEO's catalogue\n",
    "[Back to top](#TOC_TOP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to download the data from the WEkEO catalogue : <a href=\"https://www.wekeo.eu/data?view=catalogue&initial=1\" target=\"_blank\">WEkEO Catalogue</a>. To do so, we can run a small python script which summarizes the all the options :\n",
    "- time period\n",
    "- tile name : (Var region, for use cas 1)\n",
    "\n",
    "If you need any help with the Harmonized Data Access (HDA), WEkEO provides a well guided documentation  <a href=\"https://www.wekeo.eu/docs/harmonised-data-access-api\" target=\"_blank\">here</a>.\n",
    "\n",
    "Once all the data is downloaded, we need to unzip the file that will be usefull to our use cases :\n",
    "\n",
    "- band 4 :\n",
    "- band 8 :\n",
    "- cloud mask : \n",
    "\n",
    "The result of both processes gives us everything we need to start our process. The data is stored in the S2_data folder. The next step is to store the names of all these files into a list \n",
    "\n",
    "**Note:** You can go through the S2_data folder and ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files =  0\n",
      "number of acquisitions =  0\n"
     ]
    }
   ],
   "source": [
    "spatial_files = []\n",
    "directory = 'S2_data/Lot/'\n",
    "for path, subdirs, files in os.walk(directory):\n",
    "    for name in files:\n",
    "        if name[-5:] == \"0.gml\" or name[-3:] == \"jp2\":\n",
    "            file_path = os.path.join(path, name)\n",
    "            spatial_files.append(file_path)\n",
    "print('number of files = ', len(spatial_files))\n",
    "print('number of acquisitions = ', int(len(spatial_files)/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now a list _`spatial_files`_ containing all file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='section2'></a>2. Generate the time series : compute NDVI and cloud mask\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NDVI is ...\n",
    "\n",
    "<center>$NDVI = \\frac{NIR - RED}{NIR + RED}$</center>\n",
    "    \n",
    "\n",
    "The following piece of code will run through every single file and compute the NDVI and the cloud mask for every acquisition. Here is an explanation of the important output of the cell :\n",
    "    \n",
    "- ndvi_stack\n",
    "- clc_stack\n",
    "- bbox\n",
    "- timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_32 = bbox.transform(CRS.UTM_31N)\n",
    "\n",
    "timestamp = []\n",
    "for i in range(0, len(spatial_files), 3):\n",
    "    print(\"Processing file =\", i, ',', i+1, ' &', i+2)\n",
    "    year = spatial_files[i][4:8]\n",
    "    month = spatial_files[i][9:11]\n",
    "    day = spatial_files[i][11:13]\n",
    "\n",
    "    jp1 = rasterio.open(zipfiles[i])\n",
    "    jp2 = rasterio.open(zipfiles[i+1])\n",
    "    \n",
    "    jp1_clipped_r, jp1_transform = rasterio.mask.mask(jp1, [bbox_32.geometry], crop=True)\n",
    "    out_meta = jp1.meta\n",
    "    jp2_clipped_r, jp2_transform = rasterio.mask.mask(jp2, [bbox_32.geometry], crop=True)\n",
    "    \n",
    "    jp1_clipped = jp1_clipped_r.squeeze()\n",
    "    jp2_clipped = jp2_clipped_r.squeeze()\n",
    "    jp1_clipped = jp1_clipped.astype('int16')\n",
    "    jp2_clipped = jp2_clipped.astype('int16')\n",
    "\n",
    "    ndvi = ((jp2_clipped - jp1_clipped) / (jp2_clipped + jp1_clipped)).astype('float32')\n",
    "    try:\n",
    "        clm = gpd.read_file(spatial_files[i+2])\n",
    "\n",
    "        clm_clipped = clm.intersection(bbox_32.geometry)\n",
    "        clm_clipped = clm_clipped[~clm_clipped.is_empty]\n",
    "        \n",
    "        if len(clm_clipped.index) == 0:\n",
    "            clip_clm = np.zeros(jp1_clipped.shape)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            out_meta.update({\"height\": jp1_clipped_r.shape[1],\n",
    "                 \"width\": jp1_clipped_r.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "            with rasterio.open(\"file.jp2\", \"w\", **out_meta) as dest:\n",
    "                dest.write(jp1_clipped_r)\n",
    "            g = rasterio.open(\"file.jp2\")\n",
    "            clip_clm, _ = rasterio.mask.mask(g, clm_clipped)\n",
    "\n",
    "        clc_mask = np.where(clip_clm <= 0, 0, 1).astype('uint8')\n",
    "\n",
    "    except ValueError:\n",
    "        clip_clm = np.zeros(jp1_clipped.shape)\n",
    "        clc_mask = np.where(clip_clm <= 0, 0, 1).astype('uint8')\n",
    "    \n",
    "    if i==0:\n",
    "        ndvi_stack = np.expand_dims(ndvi, axis=0)\n",
    "        clc_mask_stack = np.expand_dims(clc_mask.squeeze(), axis=0)\n",
    "    else:\n",
    "        ndvi_stack = np.vstack((ndvi_stack, np.expand_dims(ndvi, axis=0)))\n",
    "        clc_mask_stack = np.vstack((clc_mask_stack, np.expand_dims(clc_mask.squeeze(), axis=0)))\n",
    "\n",
    "    timestamp.append(datetime(int(year), int(month), int(day)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ndvi_stack.shape)\n",
    "print(clc_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the dimension of both variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch = EOPatch()\n",
    "\n",
    "eopatch[FeatureType.DATA, \"NDVI\"] = np.expand_dims(ndvi_stack, axis=3)\n",
    "eopatch[FeatureType.MASK, \"CLM\"] = np.expand_dims(clc_mask_stack, axis=3)\n",
    "eopatch[FeatureType.BBOX] = BBox(bbox_32.geometry.bounds, CRS.UTM_31N)\n",
    "eopatch[FeatureType.TIMESTAMP] = timestamp\n",
    "\n",
    "eopatch.save('Patches/Var/Raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eopatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='section3'></a>3. Superpixel segmentation of the area of interest\n",
    "[Back to top](#TOC_TOP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmenting in superpixels has two major benefits. The first one is that we considerably reduce the dimension and so the number of time series we will have to process. The second reason is that, from an analytic point of view, it has no real benefit to proceed pixel by pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slic_segmentation_task = SlicSegmentationTask((FeatureType.DATA, 'NDVI_STANDARDIZED'), \n",
    "                                       (FeatureType.MASK_TIMELESS, 'SUPER_PIXELS'),\n",
    "                                      n_segments=10000, compactness=0.0001, sigma=1)\n",
    "\n",
    "raster_to_vector_task = RasterToVectorTask(features=(FeatureType.MASK_TIMELESS, 'SUPER_PIXELS', 'SUPER_PIXELS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the NDVI\n",
    "eopatch.data['NDVI_STANDARDIZED'] = stats.zscore(eopatch.data['NDVI'], nan_policy='omit')\n",
    "\n",
    "# freeing memory\n",
    "del eopatch.data['NDVI']\n",
    "\n",
    "# execute the superpixel task\n",
    "eopatch = slic_segmentation_task.execute(eopatch)\n",
    "eopatch.mask_timeless['SUPER_PIXELS'] = eopatch.mask_timeless['SUPER_PIXELS'].astype(np.int32)\n",
    "# execute the raster to vector task\n",
    "eopatch = raster_to_vector_task.execute(eopatch)\n",
    "\n",
    "# save the processed eopatch\n",
    "eopatch.save(\"/home/thomas/work/Etude CNES/WEkEO data/Communes Lot processed/Bellefont-La Rauze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print result of the segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='section4'></a>4. Compute the NDVI mean and cloud mask mean for each superpixel\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to construct our time series. Each superpixel will have his own time serie from January 2018 to December 2021. To do so, we need to compute the NDVI mean of every pixel contained in each superpixel. We proceed the same way for the cloud mask. \n",
    "\n",
    "However, it is possible that for a specific date, there is too much cloud coverage on a superpixel, meaning that the NDVI value computed is not relevant. \n",
    "\n",
    "What we do is, if the mean of the cloud coverage of one superpixel at a specific date is superior to 0.2, then we set to NaN the NDVI mean of the corresponding superpixel and date.valid_data, dates = get_valid_data(eopatch=eopatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data, dates = get_valid_data(eopatch=eopatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now constructed our NDVI time series. valid_data is shape (..). (..) is the number of Sentinel-2 acquisition (e.g. dates) and (..) is the number of superpixels. Each superpixel has his own NDVI time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='section5'></a>5. Filtering : keep only forest superpixels\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area of interest (..) is not full forest area. This means that among our time series, there are some relevant to analyse in our case. In this section, you can apply a filter in order to only keep the forest time series.\n",
    "\n",
    "- shapefile : file where is stored the polygons that delimit the forest area in the Var departement (France).\n",
    "- filter_percentage : percentage to which we keep a time series. If one superpixel is covered of this percentage or more of forest area, it is kept. Otherwise, it is dropped. Default is 0.8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_forest, ts_indices_preserved = get_forest_time_series(eopatch=eopatch, shapefile='../../work/Etude CNES/ForÃªts Lot/FORMATION_VEGETALE_D046.shp', filter_percentage=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print forest shapefile of the aoi and next to it the superpixels kept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='section6'></a>6. Apply BFAST algorithm to all remaining time series\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Little paragraph on how BFAST works\n",
    "\n",
    "+ links to documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_train = datetime(2020,1,1)\n",
    "start_monitor = datetime(2021,1,1)\n",
    "end_monitor = datetime(2021,6,30)\n",
    "bfast_model, valid_data_f, dates_f = set_bfast_params(valid_data, dates, ts_indices_preserved, end_train, start_monitor, end_monitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "breaks, magnitudes, means, valids = execute_bfast(bfast_model, valid_data_f, dates_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'breaks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-33fe5a1fee10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"number of breaks detected :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbreaks\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"percentage of time series detected with an anomaly :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbreaks\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbreaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'breaks' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"number of breaks detected :\", (breaks>0).sum())\n",
    "print(\"percentage of time series detected with an anomaly :\", ((breaks>0).sum()/len(breaks))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='section7'></a>7. USE CASE 1 : Forest fire detection in Var region (France)\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = organise_results(time_series_forest, dates_f, start_monitor, breaks, magnitudes)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint_df = group_by_breakpoints(results)\n",
    "breakpoint_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='section8'></a>8. USE CASE 2 : Monitor parasite attacks on trees, example in Lot region (France)\n",
    "[Back to top](#TOC_TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### Challenge:\n",
    "\n",
    "A final section of your notebook could invite the user to try and adapt your notebook for their own purposes. This is not necessary but can really help people to learn by applying their new knowled\n",
    " <div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# Enter your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "author": "Ben Loveday, Hayley Evers-King",
  "description": "This Jupyter Notebook discusses the radiance and brightness temperature bands in SLSTR level-1B products.",
  "github": "https://github.com/wekeo/learn-slstr/blob/master/1_SLSTR_introductory/1_4_SLSTR_bands_imagery.ipynb",
  "image": "../img/thumbs/1_4_SLSTR_bands_imagery_thumb.png",
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "link": "https://jupyterhub-wekeo.apps.eumetsat.dpi.wekeo.eu/hub/user-redirect/lab/tree/public/ocean/learn-slstr/1_SLSTR_introductory/1_4_SLSTR_bands_imagery.ipynb",
  "tags": {
   "domain": "Ocean",
   "platform": "Sentinel-3",
   "sensor": "SLSTR",
   "tags": [
    "Top-of-atmosphere radiance",
    "Brightness temperature"
   ]
  },
  "title": "SLSTR bands and imagery"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
